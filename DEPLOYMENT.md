# üöÄ Guide de D√©ploiement

## Option 1 : Streamlit Cloud (Recommand√©)

**Streamlit Cloud est gratuit et parfait pour les applications Streamlit.**

### √âtapes de d√©ploiement :

1. **Connecter votre repo GitHub √† Streamlit Cloud**
   - Allez sur : https://streamlit.io/cloud
   - Cliquez sur "New app"
   - Connectez votre compte GitHub
   - S√©lectionnez le repository : `louiscbns/post-call-monitoring`

2. **Configuration**
   - **Branch** : main
   - **Main file path** : `app.py`
   - **Python version** : 3.9+

3. **Variables d'environnement**
   Dans Streamlit Cloud, ajoutez vos secrets :
   ```
   ROUNDED_API_KEY=votre_cl√©_rounded
   OPENAI_API_KEY=votre_cl√©_openai
   ANTHROPIC_API_KEY=votre_cl√©_anthropic (optionnel)
   GOOGLE_API_KEY=votre_cl√©_google (optionnel)
   ```

4. **D√©ploiement automatique**
   - Streamlit Cloud d√©ploie automatiquement √† chaque push
   - Votre app sera accessible sur : `https://<votre-app>.streamlit.app`

### Avantages :
- ‚úÖ Gratuit
- ‚úÖ D√©ploiement automatique depuis GitHub
- ‚úÖ Gestion native des secrets
- ‚úÖ HTTPS automatique
- ‚úÖ Pas de configuration serveur

---

## Option 2 : Vercel (API seulement)

Si vous voulez vraiment utiliser Vercel, vous devez convertir l'app en API REST avec Flask ou FastAPI.

### Cr√©er une API Flask

Cr√©ez un fichier `api.py` :

```python
from flask import Flask, request, jsonify
from main import PostCallMonitoringSystem
import os
from dotenv import load_dotenv

load_dotenv()

app = Flask(__name__)

@app.route('/api/analyze', methods=['POST'])
def analyze_call():
    data = request.json
    call_id = data.get('call_id')
    model = data.get('model', 'gpt-4o-mini')
    
    try:
        system = PostCallMonitoringSystem(model_name=model)
        result = system.analyze_call_from_id(call_id)
        
        if result:
            return jsonify({
                'success': True,
                'call_id': result.call_id,
                'problem_detected': result.problem_detected,
                'problem_type': result.problem_type,
                'tags': result.tags,
                'summary': result.summary
            })
        else:
            return jsonify({
                'success': False,
                'error': 'Analysis failed'
            }), 400
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/health', methods=['GET'])
def health():
    return jsonify({'status': 'ok'})
```

### Configuration Vercel

Cr√©ez `vercel.json` :

```json
{
  "version": 2,
  "builds": [
    {
      "src": "api.py",
      "use": "@vercel/python"
    }
  ],
  "routes": [
    {
      "src": "/api/(.*)",
      "dest": "api.py"
    }
  ],
  "env": {
    "ROUNDED_API_KEY": "@rounded_api_key",
    "OPENAI_API_KEY": "@openai_api_key"
  }
}
```

### D√©ploiement sur Vercel

```bash
npm i -g vercel
vercel
```

---

## Option 3 : Railway ou Render

Ces plateformes supportent nativement les applications Streamlit.

### Railway

1. Cr√©ez un compte sur https://railway.app
2. New Project ‚Üí Deploy from GitHub
3. S√©lectionnez votre repo
4. Ajoutez les variables d'environnement
5. Votre app sera d√©ploy√©e automatiquement

### Render

1. Cr√©ez un compte sur https://render.com
2. New ‚Üí Web Service
3. Connectez GitHub
4. Configuration :
   - Build Command : `pip install -r requirements.txt`
   - Start Command : `streamlit run app.py`
5. D√©ploiement automatique

---

## Recommandation

**Utilisez Streamlit Cloud** - c'est la solution la plus simple et la plus adapt√©e pour votre application Streamlit.

Souhaitez-vous que je vous guide √† travers le d√©ploiement sur Streamlit Cloud ?

